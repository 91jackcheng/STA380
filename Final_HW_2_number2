---
title: "R_hw2_qs4"
author: "steven"
date: "August 18, 2017"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question 2
For this question, we decided to use Naive Bayes and Random Forest methods because they are considered as common ways to deal with text mining problems. After we performed these methods, we would compare them using prediction accuracies in the test data. Our goal in this question is to perform these two methods and use a better method to predict the author names given in the testing data.
## Naive Bayes method 

```{r cars}
library(tm)
```

We defined a function called readerPlain to read the content of text files.

```{r}
readerPlain = function(fname){
  readPlain(elem=list(content=readLines(fname)),id=fname, language='en') }
```

At first, we loaded the training and testing directory.

```{r}
train_dirs = Sys.glob("~/Documents/STA380/ReutersC50/C50train/*")
test_dirs = Sys.glob("~/Documents/STA380/ReutersC50/C50test/*")
```

## The Sparse matrix
For training set

```{r}
file_list_train = NULL
labels_train = NULL
y_train = NULL
for(author in train_dirs) {
  author_name = tail(strsplit(author,split="/")[[1]],1)
  files_to_add = Sys.glob(paste0(author, '/*.txt'))
  file_list_train = append(file_list_train, files_to_add)
  labels_train = append(labels_train, rep(author_name, length(files_to_add)))
}
```

By using the for loop here, we got the author name for each txt files in the training data set and also the file path toward each text files for each author in the training set.

We then combined all the text files in the training set and made it into corpus by using Corpus() function.

```{r}
train_docs = lapply(file_list_train, readerPlain) 
names(train_docs) = file_list_train
names(train_docs) = sub('.txt', '', names(train_docs))
my_corpus_train = Corpus(VectorSource(train_docs))
```

For the testing set, we repeated what we did for the training set and made a corpus for the testing data.

```{r}
file_list_test = NULL
labels_test = NULL
for(author in test_dirs) {
  author_name = tail(strsplit(author,split="/")[[1]],1)
  files_to_add = Sys.glob(paste0(author, '/*.txt'))
  file_list_test = append(file_list_test, files_to_add)
  labels_test = append(labels_test, rep(author_name, length(files_to_add)))
}

test_docs = lapply(file_list_test, readerPlain) 
names(test_docs) = file_list_test
names(test_docs) = sub('.txt', '', names(test_docs))
my_corpus_test = Corpus(VectorSource(test_docs))

```

## Data Preprocessing
For train data

```{r}

my_corpus_train = tm_map(my_corpus_train, content_transformer(tolower)) 
# make everything lowercase
my_corpus_train = tm_map(my_corpus_train, content_transformer(removeNumbers)) 
# remove numbers
my_corpus_train = tm_map(my_corpus_train, content_transformer(removePunctuation)) 
# remove punctuation
my_corpus_train = tm_map(my_corpus_train, content_transformer(stripWhitespace)) 
# remove excess white-space
my_corpus_train = tm_map(my_corpus_train, content_transformer(removeWords), stopwords("SMART"))
```

After we removed numbers, punctuations, excess white-spaces and stopwords, we got our new corpus for the training set.

```{r}
# for test data
my_corpus_test = tm_map(my_corpus_test, content_transformer(tolower)) # make everything lowercase
my_corpus_test = tm_map(my_corpus_test, content_transformer(removeNumbers)) # remove numbers
my_corpus_test = tm_map(my_corpus_test, content_transformer(removePunctuation)) # remove punctuation
my_corpus_test = tm_map(my_corpus_test, content_transformer(stripWhitespace)) ## remove excess white-space
my_corpus_test = tm_map(my_corpus_test, content_transformer(removeWords), stopwords("SMART"))
```

## Model Prediction and Accuracy

```{r}
library('naivebayes')
```
Then We made our training and testing corpus into document term matrices.
```{r}
DTM_train = DocumentTermMatrix(my_corpus_train)
DTM_test = DocumentTermMatrix(my_corpus_test)
```

By using class functions, we finally got our sparse matrix for the training and testing sets. In addition, inspect function were used here to get access to the values inside of the sparse matrix.

```{r}
class(DTM_train)  
class(DTM_test)

inspect(DTM_train[1:10,1:20])
inspect(DTM_test[1:10,1:20])
```

We then went on removing some sparse terms in our sparse matrix for the training and testing set. After that, we converted our sparse matrices to word frequency matrices for the training and testing sets in data frame type.

```{r}
DTM_train = removeSparseTerms(DTM_train, 0.975)
DTM_test = removeSparseTerms(DTM_test, 0.975)

X_train = as.data.frame(as.matrix(DTM_train))
X_test = as.data.frame(as.matrix(DTM_test))
```

Now we tried to get an intersect of common columns that present in both training and testing sets.
We created a new training set which only contains common columns from both training and testing sets.

```{r}
common_cols = intersect(names(X_train), names(X_test))
X_train_2 =X_train[,c(common_cols)]

```

We then built the naive bayes model using the new training set and then found out its model accuracy.

```{r}

nb_train = naive_bayes(x=X_train_2, y= as.factor(labels_train),laplace=1)
train.pred = predict(nb_train, X_test)

count=0
for (i in 1:2500){
  if(train.pred[i]==labels_train[i]){
    count=count+1
  }
}
accuracy = count/2500
cat('Prediction accuracy for navie bayes method is ',accuracy)
```

Finally, We got an accuracy of 18.28% when we used the naive bayes model to predict the author names in test set.  

We noticed that we got a rather low accuracy rate using Naive Bayes. The main reason here is that the text files actually violate the assumption of independence features likelihood assumed in Naive Bayes algorithm. The probability of which word chosen in the text file is strongly related to which other words have already been chosen. 
For the reasons above, we decided to use a random forest model to get a better accuracy rate.

## Random Forest Method

We used the new training data set got from the previous section to perform the randomforest model with tree number equalts  to 100.

```{r}
library(randomForest)
set.seed(1)
rfmodel <- randomForest(x=X_train_2,y=factor(labels_train),ntree=100)
rf.pred = predict(rfmodel,newdata=X_test)
conf_matrix = table(rf.pred,labels_train)
```

Calculated the number of corrected predictions through all text files.

```{r}
count = 0
for(i in 1:dim(conf_matrix)[1]){
  count = count + conf_matrix[i,i]
}

cat('Prediction accuracy for Random Forest method is around', count/2500)
```

We used 4 different values(50,100,150,200) to figure out the best tree number for the random forest model and finally came out with our highest prediction with ntree=100 and the corresponding accuracy around 60%.



